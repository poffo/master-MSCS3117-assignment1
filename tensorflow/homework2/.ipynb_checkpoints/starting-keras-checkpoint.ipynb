{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=2, activation='relu', input_dim=50))\n",
    "model.add(Dense(units=1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_categorical_crossentropy => target as numbers\n",
    "#categorical_crossentropy => target as binary\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTQdK9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181ff1f510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_examples = 50\n",
    "# linspace: generates linear samples from the initial point (-2) to the final point (4)\n",
    "X = np.array([np.linspace(-2, 4, num_examples), np.linspace(-6, 6, num_examples)])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(X[0], X[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.        , -1.87755102, -1.75510204, -1.63265306, -1.51020408,\n",
       "        -1.3877551 , -1.26530612, -1.14285714, -1.02040816, -0.89795918,\n",
       "        -0.7755102 , -0.65306122, -0.53061224, -0.40816327, -0.28571429,\n",
       "        -0.16326531, -0.04081633,  0.08163265,  0.20408163,  0.32653061,\n",
       "         0.44897959,  0.57142857,  0.69387755,  0.81632653,  0.93877551,\n",
       "         1.06122449,  1.18367347,  1.30612245,  1.42857143,  1.55102041,\n",
       "         1.67346939,  1.79591837,  1.91836735,  2.04081633,  2.16326531,\n",
       "         2.28571429,  2.40816327,  2.53061224,  2.65306122,  2.7755102 ,\n",
       "         2.89795918,  3.02040816,  3.14285714,  3.26530612,  3.3877551 ,\n",
       "         3.51020408,  3.63265306,  3.75510204,  3.87755102,  4.        ],\n",
       "       [-6.        , -5.75510204, -5.51020408, -5.26530612, -5.02040816,\n",
       "        -4.7755102 , -4.53061224, -4.28571429, -4.04081633, -3.79591837,\n",
       "        -3.55102041, -3.30612245, -3.06122449, -2.81632653, -2.57142857,\n",
       "        -2.32653061, -2.08163265, -1.83673469, -1.59183673, -1.34693878,\n",
       "        -1.10204082, -0.85714286, -0.6122449 , -0.36734694, -0.12244898,\n",
       "         0.12244898,  0.36734694,  0.6122449 ,  0.85714286,  1.10204082,\n",
       "         1.34693878,  1.59183673,  1.83673469,  2.08163265,  2.32653061,\n",
       "         2.57142857,  2.81632653,  3.06122449,  3.30612245,  3.55102041,\n",
       "         3.79591837,  4.04081633,  4.28571429,  4.53061224,  4.7755102 ,\n",
       "         5.02040816,  5.26530612,  5.51020408,  5.75510204,  6.        ]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 50)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(2, num_examples).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEf9JREFUeJzt3W+MXNV9xvHvU9uEdVK0SDiKWOOa\nqI0bAlQmG0RrtU0NqSm4gPKKVkS0eWG1CilUiakpL8i7WKJKU4molUWpKoGapMQxqKQFIqetigRl\njUmIY4gQqcFLIzZqnbRhCzb8+mLXsOyd2bkz98yec2eej2TJOzu+c0bWPHPO754/igjMzJb6mdwN\nMLPyOBjMrMLBYGYVDgYzq3AwmFmFg8HMKpIEg6Q/lnRE0ncl/Z2kM1Nc18zyaBwMkqaAPwKmI+JC\nYA1wfdPrmlk+qYYSa4EJSWuB9cDLia5rZhmsbXqBiJiV9GfAi8A88EhEPLLSvznnnHNi8+bNTV/a\nzPp06NChH0XEhl7PaxwMks4GrgXOB04Afy/phoi4d9nzdgG7ADZt2sTMzEzTlzazPkk6Vud5KYYS\nVwA/iIi5iDgJ7Ad+ZfmTImJfRExHxPSGDT0Dy8wyShEMLwKXSVovScDlwNEE1zWzTBoHQ0Q8AdwP\nPAU8s3jNfU2va2b5NK4xAETEHcAdKa5lZvl55qOZVSTpMZhZ1YHDs9z58HO8fGKecycn2L1jC9dt\nncrdrFocDGZDcODwLLftf4b5k28AMHtintv2PwPQinDwUMJsCO58+Lm3QuG0+ZNvcOfDz2VqUX8c\nDGZD8PKJ+b4eL42DwWwIzp2c6Ovx0jgYzIZg944tTKxb847HJtatYfeOLZla1B8XH82G4HSB0Xcl\nzOwdrts61ZogWM5DCTOrcDCYWYWDwcwqHAxmVuFgMLMKB4OZVTgYzKzCwWBmFQ4GM6vwzEezIWrr\nZi2pzq6clHS/pGclHZX0yymua9ZmpzdrmT0xT/D2Zi0HDs/mblpPqYYSfwH8U0T8IvBLePt4s1Zv\n1pLiJKqzgF8Dfg8gIl4HXm96XbO2m+2yKUu3x0uSosfwfmAO+BtJhyXdLendCa5r1mprpL4eL0mK\nYFgLXAL8ZURsBX4K7Fn+JEm7JM1Impmbm0vwsmZleyOir8dLkiIYjgPHF0+kgoVTqS5Z/iSfXWnj\nZqrLNm7dHi9JiiPqfgi8JOn0nlWXA99rel2ztut3e7cDh2fZtvcg5+95iG17D2a9e5FqHsOngfsk\nnQG8APx+ouuatVY/27uVdg6FIsN4Z3p6OmZmZlb9dc1KtW3vwY53K6YmJ3hsz/ZkryPpUERM93qe\np0SbFaC0cygcDGYFKO0cCgeDWQFKO4fCi6jMClDaORQOBrNClHQOhYcSZlbhHoNZYkv3YJhcv44I\n+PH8yezDg344GMwSWj5R6b9fPfnW73JPWuqHg8EsoU57MCx1ej+GVMEwrB2iHAxmCdWZkJRq0tIw\np1G7+GiWUJ0JSakmLQ1zhygHg1lCnSYqLZVy0tIwp1E7GMwSum7rFJ//+EVMTU4g4Oz165icWIdY\nWBD1+Y9flKy+MMxp1K4x2FvautV5aVZrotLuHVveUWOAdD0SB4MB5e0HYL0Ncxq1g8GAlQtZDoZy\nDat34hqDAeXtB2B5ORgMKG8/AMvLwWBAefsBWF7JagyS1gAzwGxE7Ex1XVsdpe0HYHmlLD7ezMKZ\nlWclvKatopL2A7C8Up12vRG4Grg7xfXMLK9UNYYvArcCb3Z7go+oM2uPFKdd7wReiYhDkj7a7XkR\nsQ/YBwvnSjR9XbNxstqzUlPUGLYB10i6CjgTOEvSvRFxQ4Jrm429HLNSU5xdeVtEbIyIzcD1wEGH\ngvWrpHMbSzPM5dXdeEq0ZdeGdRo5F5jlmJWadIJTRPyz5zBYv3J8I/bjdHDNnpgneDu4VqtXk2NW\nqmc+Wna512n0GsbkDq4cs1I9lLDszp2c6HjS82qs06gzjMkdXDlmpToYLLthbjjSS53l5jmD67TV\nnpXqoYRlt3w7tEG2QBv0rkad3sA4LjBzj8GK0OQbscldjTq9gXFcYOZgsNZZfuvwp6+dGnj3qbrD\nmHFbYOZgsFbp1Dvopk5xcBx7A3U4GKxVeh0Bt1Td4uC49QbqcDBY0ZYPG1bqISw16sXBYXMwWLE6\nDRsEdFqae/b6daw/Y62HA4k4GKxYnYYNAZVwmFi3hjt++0MOgoQ8j8GK1a14GNBozoP15h6DFatb\nTWFqcoLH9mzP0KLx4R6DFWscZxyWwj0GK8JK+x00nWPgw3r752Cw7HpNaW7yIS5tE5i2hJSHEpbd\nMPc7yL2XwlK5N3zph4PBshvmfge591JYqqSQ6sXBYNkNc+uykg7rLSmkemkcDJLOk/QtSUclHZF0\nc4qG2fgY5t2Hku5slBRSvaToMZwCPhMRHwQuAz4l6YIE17UxkWKjlhzX7ldJIdWLItIeCiXpAeCu\niHi023Omp6djZmYm6etaeyre4yz3/5GkQxEx3fN5KYNB0mbgX4ELI+Iny363C9gFsGnTpg8fO3Ys\n2eta9bYcLHwbebqwLVU3GJIVHyW9B/gacMvyUICFsysjYjoipjds2JDqZW1RmyreVr4kwSBpHQuh\ncF9E7E9xTetPmyreVr4UdyUE/DVwNCK+0LxJNog2VbytfCl6DNuATwDbJT29+OeqBNe1PrSp4m3l\na7xWIiL+jYW9Mywjb2pqKXkR1QjxpqaWiqdEm1mFg8HMKhwMZlbhYDCzCgeDmVU4GMyswsFgZhWe\nx2BJ5V5WbGk4GCyZ0nZkXs6hVZ+HEpZMyUu/27RDcwkcDJZMyUu/Sw6tEjkYLJmSl36XHFolcjBY\nMiUv/S45tErkYLAVHTg8y7a9Bzl/z0Ns23twxTF5STsyL1dyaJXIdyWsq0HuMpS69Nv7VfTHwWBd\nrVSwa+MHqtTQKpGHEtaVC3bjyz0G6+rcyQlmO4RAyoKdJx2VKdX28VdKek7S85L2pLim5Tfsgp0n\nHZWrcY9B0hrgS8DHgOPAk5IejIjvNb225dWtYAewbe/Bxt/yo1bDGCUphhKXAs9HxAsAkr4MXAs4\nGEbA8oJd0/UQS4cO3Q5HdA0jvxRDiSngpSU/H1987B0k7ZI0I2lmbm4uwctaN/3MPehXk6nFy4cO\n3XjSUX4pegydzpSo/L9HxD5gHyycdp3gda2DTt/ou+//Np978Ag/nj/ZuMDX5E5Fp1BZzpOOypAi\nGI4D5y35eSPwcoLr2gA6ffhOvhGcmD8JNF8K3c+diuV3HDr9u9O0eA3flShDiqHEk8AvSDpf0hnA\n9cCDCa5rA6jzzd1kVWHdOxWd7jh0O65sanKCH+y9msf2bHcoFCLFEXWnJN0EPAysAe6JiCONW2YD\n6fXNfNqgBb66U4s79VyChZ7B0nGkhw5lSjLBKSK+AXwjxbWsmd07tryjxtBNkwJfnanF3YInWOgh\neEJT2TzzccQs/0afXL+O//2/U5x88+3v6dX4lu7Wc5manOCxPdtX/LeeDZmfg2EEdZp7sNoftE49\nlzqBVPq+kePCwTAGcqwqHHSZs2dDlsHBYEMzSCB5RWcZvOzaiuIt2MrgHkPh2lKIS9XOQWsTlpaD\noWBtKcSlbKe3YCuDg6FgbSnEpW6nt2DLzzWGgrWlENeWdlp97jEUrC1bq61GO211ucdQsLZsreYz\nG0aPewwFG3Yhrk5toE6PwgXD0eNgKNwwC3G9agP93G1wwXC0eCgxxnpNJvIJ0ePLwTDGetUGfLdh\nfDkYxlivQ2g9PXl8ucYw5laqDXh68vhyMFhXvtswvhwMtiLfbRhPjWoMku6U9Kyk70j6uqTJVA0z\ns3yaFh8fBS6MiIuB7wO3NW+StcEwT7uy/BoFQ0Q8EhGnFn98nIXDZmzE+ZTq0ZeyxvBJ4Cvdfilp\nF7ALYNOmTQlf1oZt+bToV18/1Yrl4Da4nsEg6ZvA+zr86vaIeGDxObcDp4D7ul3HZ1cO17B2euo0\nLbobT3waHT2DISKuWOn3km4EdgKXR4Q/8BkMc6enOgfRnuaJT6Oj6V2JK4E/Aa6JiFfTNMn6Ncw1\nDXV7AZ74NFqa1hjuAt4FPCoJ4PGI+IPGrWqJUjZqHeaahm6bsExOrOPd71qb/b3bcDQKhoj4+VQN\naZuSNmod5g5K3aZFf+6aDzkIRpgXUQ2opCXJw9xBqddCKxtNnhI9oJKWJA97TYOnRY8fB8OAStsA\n1R9eS8lDiQF5A1QbZe4xDMhLkm2UORgacPfdRpWHEmZW4WAwswoHg5lVOBjMrMLFxxFSytoNaz8H\nw4goae2GtZ+DYYk2f+PWOaDWrC4Hw6K2f+OWtHbD2s/Fx0UlrZYchI+Ts5RGIhhSbGXe7Zt19sR8\nK3Y/9toNS6n1Q4lUQ4BuqyWBVgwpvHbDUlKO/Vunp6djZmYmybW27T3Y8QM9NTnBY3u2177O8oBp\nej2zEkk6FBHTvZ7X+h5DqqLb6W/WW77ydJLrmbVZkhqDpM9KCknnpLheP1IW3a7bOsWUi3hmzYNB\n0nnAx4AXmzenf6mLbi7imaUZSvw5cCvwQIJr9S110c1FPLOGxUdJ17BwAtXNkv4DmI6IH3V57tKz\nKz987NixgV/XzAaTrPi40tmVwJ8Cv1mnQaN+dmWbp1ObLTfw2ZWSLgLOB769eArVRuApSZdGxA+T\ntrJwJUyndjBZSgMXHyPimYh4b0RsjojNwHHgknELBcg/nfp0MM2emCd4O5jaMGPTyjQSU6Jzy72A\nKXcw2ehJFgyLPYeOhcdRl3sBU+5gstFTZI8hxaKo1ZR77kPuYLLRU1wwtHG8XPfg12EFXu5gstFT\n3FqJtu5E1OvwmRR3LrrdefCkLEutuGBo43i5zq3CpoHXK1h8KpalVNxQom3j5bpDn6aB5zsPtpqK\nC4a2jZfrfmCbBl4be1LWXsUFQ91CXinqfmCbBl7belLWbsXVGKBdp0h32xJu+Qe2aYFw944tlR2m\nSu5JWbsVGQxt0s8Htkng+c6DrSYHQ0Or+YFtU0/K2s3BkIA/sDZqiis+mll+DgYzq3AwmFmFg8HM\nKhwMZlbhYDCzCgeDmVU4GMysovEEJ0mfBm4CTgEPRcStjVu1yFuim+XRKBgk/QZwLXBxRLwm6b1p\nmlXGWQ1m46rpUOIPgb0R8RpARLzSvEkLvDGJWT5Ng+EDwK9KekLSv0j6SLcnStolaUbSzNzcXM8L\ne2MSs3yanl25FjgbuAz4CPBVSe+PDifl9nt2Zd19DswsvZ49hoi4IiIu7PDnARaOpdsfC/4deBM4\nJ0XD2rbFm9koaTqUOABsB5D0AeAMIMlpVG3b4s1slDS9XXkPcI+k7wKvAzd2GkYMyvscmOXRKBgi\n4nXghkRtMbNCeAcn68oTzMaXg8E68gSz8ea1EtaRJ5iNN/cYVjDOXWlPMBtv7jF0UfdMylHlk6/G\nm4Ohi3HvSnuC2XjzUKKLce9K++Sr8eZg6MJrNTzBbJx5KNGFu9I2ztxj6MJdaRtnDoYVuCtt48pD\nCTOrcDCYWYWDwcwqHAxmVuFgMLMKJdxwqf6LSnPAsVV/4cGdQ6It6zLz+yhLjvfxcxGxodeTsgRD\n20iaiYjp3O1oyu+jLCW/Dw8lzKzCwWBmFQ6GevblbkAifh9lKfZ9uMZgZhXuMZhZhYOhJkl3SnpW\n0nckfV3SZO421SXpSknPSXpe0p7c7RmUpPMkfUvSUUlHJN2cu02DkrRG0mFJ/5C7LZ04GOp7FLgw\nIi4Gvg/clrk9tUhaA3wJ+C3gAuB3JF2Qt1UDOwV8JiI+yMJByp9q8Xu5GTiauxHdOBhqiohHIuLU\n4o+PAxtztqcPlwLPR8QLiyeHfRm4NnObBhIR/xkRTy3+/X9Y+GC1bl28pI3A1cDdudvSjYNhMJ8E\n/jF3I2qaAl5a8vNxWvhhWk7SZmAr8ETelgzki8CtLJwOXyRv1LKEpG8C7+vwq9sj4oHF59zOQpf2\nvtVsWwPq8Firb0VJeg/wNeCWiPhJ7vb0Q9JO4JWIOCTpo7nb042DYYmIuGKl30u6EdgJXJ7yVO8h\nOw6ct+TnjcDLmdrSmKR1LITCfRGxP3d7BrANuEbSVcCZwFmS7o2Iog6H9jyGmiRdCXwB+PWImMvd\nnrokrWWhWHo5MAs8CfxuRBzJ2rABSBLwt8B/RcQtudvT1GKP4bMRsTN3W5ZzjaG+u4CfBR6V9LSk\nv8rdoDoWC6Y3AQ+zUKz7ahtDYdE24BPA9sX/g6cXv3ktMfcYzKzCPQYzq3AwmFmFg8HMKhwMZlbh\nYDCzCgeDmVU4GMyswsFgZhX/DzWtpnl50Kp5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181ff30410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate noisy on the linear data\n",
    "\n",
    "X += np.random.randn(2, num_examples)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(X[0], X[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 50)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(np.random.randint(1, size=(50)), num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.transpose(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_36_input to have shape (None, 50) but got array with shape (50, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-702dc75cb929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1556\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1410\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1411\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_36_input to have shape (None, 50) but got array with shape (50, 1)"
     ]
    }
   ],
   "source": [
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(X[0], y, epochs=5, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 223us/step - loss: 0.7233 - acc: 0.4980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.7029 - acc: 0.5140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.6996 - acc: 0.5210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.6909 - acc: 0.5370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.6837 - acc: 0.5580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.6826 - acc: 0.5490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.6818 - acc: 0.5460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.6753 - acc: 0.5960\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.6762 - acc: 0.5730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.6662 - acc: 0.5980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181f3efc50>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 243us/step - loss: 2.3535 - acc: 0.0990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.3156 - acc: 0.1070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 2.3028 - acc: 0.1160\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.2896 - acc: 0.1250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 2.2815 - acc: 0.1330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 2.2718 - acc: 0.1400\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 2.2612 - acc: 0.1470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 2.2531 - acc: 0.1650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 2.2435 - acc: 0.1670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 2.2359 - acc: 0.1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181f1a5a10>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 286us/step - loss: 2.3541 - acc: 0.1080\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3547 - acc: 0.0870\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3411 - acc: 0.1110\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3226 - acc: 0.1120\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3234 - acc: 0.1120\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.3124 - acc: 0.1180\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3057 - acc: 0.1250\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3086 - acc: 0.1040\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3111 - acc: 0.1050\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3044 - acc: 0.1150\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.3181 - acc: 0.101 - 0s 27us/step - loss: 2.3041 - acc: 0.1140\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3024 - acc: 0.1220\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.3035 - acc: 0.1190\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3055 - acc: 0.1090\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 2.2987 - acc: 0.156 - 0s 25us/step - loss: 2.2998 - acc: 0.1180\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.2943 - acc: 0.1230\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.2939 - acc: 0.1280\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.3011 - acc: 0.1120\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.2951 - acc: 0.1290\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.2957 - acc: 0.1190\n",
      "100/100 [==============================] - 0s 916us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
